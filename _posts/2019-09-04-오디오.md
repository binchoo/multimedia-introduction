# 오디오

## 아날로그 소리

가청 주파수 대역의 파동이 매질의 떨림으로써 전달되고, 떨림이 내이를 자극하면 소리로 인식하게 된다.

ex) 피아노의 현이 떨림 -> 공기를 통해 떨림이 전파(공기 압력의 변화) -> 귀의 고막이 떨림 -> 소리로 인지

### 파동으로서의 소리

#### 파동의 성질

1. 반사 : 튕겨나오기
2. 회절 : 방해물에 의해 진행방향이 바뀐다
3. 굴절 : 매질이 달라지면서 진행 속도가 변한다.

#### 파동의 요소

1. 주기 $T$ : 매질점이 1회 진동하는데 걸린 시간
2. 주파수 $f$ : 단위시간 동안 진행되는 파동의 수
3. 파장 $ \lambda$ :  1회 진동으로 파동이 이동한 거리 (**정의역이 위치일 때 알수있지**)
4. 진폭 $A$ : 0을 기준으로 가장 멀리 떨어진 수직값
5. 속력 $v = 거리/시간 = \lambda/T = \lambda f$



- 소리는 음압의 **주기적인** 진동이다.
- 정의역은 시간 t, 치역은 음압 dB이다.
- 소리는 역학적인 파동이다. 매질(공기)이 압력을 받았다가 반작용에 의해 팽창하기 때문에 압력의 변화가 주의로 전파된다. 공기분자가 이동하는 것은 아니며 반동에 의해 제자리로 돌아온다.
- 횡파 : 파동의 진행방향과 수직으로 변위가 생긴다. ex) 팽팽한 줄 흔들면 파동이 속도v를 가지며 줄을 따라 진행한다. **줄 요소(매질)의 변위는 진행방향에 수직**으로 관찰된다.
- 종파:  파동의 **진행방향과 나란하게 매질이 운동**한다. ex)소리



### 소리의 인지

#### 귀의 구조

- 귓바퀴 : **소리를 모으는** 역할

- 외이도 : 귓구멍, 고막 **보호**, 이물질 필터

  

- 고막 : **음파에 의해 진동**함

- 청소골 : **진동을 증폭**하여 달팽이관으로 전달

- 유스타키오관 : 중이와 목구멍을 잇은 관. **압력의 평형**



- 난원창 : 고막의 **진동을 압력으로 변환** -> **압력을 림프의 진동으로 변환**
- 달팽이관 : 청세포를 이용해 진동을 느낌
- 반고리관 : 회전감각 직각 뼈닥구 3개
- 전정기관: 위치감각 림프액 주머니 2개



소리 > 귓바퀴 > 고막 > 청소골 > 달팽이관 > 청세포 > 청신경 > 대뇌



#### 소리의 강도 (Intensity) $\propto A$

큰 소리는 압력 변화가 큰 것이다. dB단위로 표현되며 B단위에 10을 더 곱해서 데시벨이 되었다.  P0는 들을 수 있는 가장 작은 음압이고 P1은 비교 대상 소리의 음압이다.
$$
dB = 10 log_{10}{p_1^2\over p_0^2}
$$

#### 귀에 들리는 소리의 크기 (Loudness)

- loudness에는 $A, f$가 관여한다. 
- 사람 귀는 4kHz 주파수의 소리에 민감하다.
-  loudness가 `n phon` 이라는 의미는 1kHz n dB에서 느껴지는 소리 크기를 말한다. 
- Equal Loudness Graph는 동일한 `phon` 값을 갖는 소리들을 이은 것이다.

#### 소리의 높낮이 (Pitch) $\propto f$

- 주파수가 다르면 귀의 울림이 일어나는 basilar membrane상 위치가 다르다. 
- 높은 주파수 음은 window 앞쪽에서 정점을 찍는다.
- 낮은 주파수 음은 window 뒤쪽에서 정점을 찍는다.
- 이걸로 섞인 소리의 주파수를 구분해 낼 수 있다. 
- 청세포가 다른 주파수의 소리를 병렬로 전달한다.

#### 소리의 마스킹 효과

어떤 소리는 특정 음압의 소리를 몇 초간 들리지 않게 하며, 특정 주파수 영역의 소리를 들을 수 없게 한다.

- Temporal Masking (t - dB)

  : 큰 소리를 듣고서 **작은 소리가 들리려면 회복시간이 필요**

- Frequency Masking (f - dB)

  : **낮은 톤의 소리는 높은 톤 소리를 효과적으로 침묵**시킨다. 마스킹 능력이 좋으면 **더 넓은 영역대의 소리를 침묵**시킨다.  두 소리의 주파수 영역 이격이 크면 마스킹이 적게 일어난다.

소리가 발생하면 시간적 & 주파수 마스킹이 일어나겠군~

- Critical Band

   : 사람의 귀가 동시에 들리는 톤을 구분하는 능력이다.

  - 낮은 주파수(톤)은 100 Hz 부터 차이를 인지할 수 있다
  - 높은 주파수(톤)은 4kHz 부터 차이를 인지할 수 있다. 표를 참고하자.
  - Critical Bandwidth는 500Hz 대역 이전은 상수(100Hz)이고 이후부터 선형적으로 증가한다.

- Bark Unit 

  : 같은 Critical Band에 포함된 소리들은 똑같은 톤으로 생각하면 된다. Critical Band #를 Bark 라하는데, Bark를 정의역으로 삼아서 Frequecy Masking 효과 영역을 나타내면 여러 바크에서 비슷한 모습을 보인다.
  
#### 소리의 방향

  두 귀로 도달하는 소리의 크기와 시간의 차이를 통해서 인지

  - IID(Interaural Intensity Difference) : 왼쪽 귀의 음악소리가 더 크게 들리면? 왼편에 있겠군.
  - ITD(Interaural Difference) : 왼쪽 귀에 음악이 먼저 도착했다면? 왼편에 있겠군.

#### 칵테일 파티 효과

동시에 여러 소리가 나도 원하는 소리만 골라 듣는게 가능한 능력

#### 하스 효과 (선행음 효과)

소리가 먼저 들리는 곳에 음원이 있다고 생각함. Ex) 강사의 목소리 & 목소리를 내보내는 스피커 소리

### 음악의 요소

1. **Pitch, 음높이**
	- 음악의 note ~= 공학의 tone 이다.
	- Pitch의 차이가 있더라도 음악엔 차이가 없다.
2. **Rhythm, 리듬**
   - 음의 길이가 듣는이에게 주는 느낌
3. **Tempo, 템포**
   - 음악의 전체적인 빠르기
4. **Contour, 윤곽**
   - 음의 올라가고 내려가는 방향성
   - 음악으로 음악검색을 할 때 컨투어를 활용한다.
   - **허밍의 피치는 원곡을 어설프게 따라하는 경우가 많은데, 컨투어는 잘 지켜지는 경향이 있음.**
5. **Timber, 음색**
   - 서로 다른 악기가 같은 피치를 내도 **음색 덕분에** 악기를 구분할 수 있다.
   - 악기 매질의 떨림이 다르기 때문
   - Loudness, Pitch를 제외한 요소들이 Timber의 요소이다.
   - **순음** : 하나의 정현파로 구성되는 음
   - **기음** : 음의 기본 주파수
   - **배음** : 기본 주파수의 정수배 파형
   - 악기의 소리는 여러 정현파의 합.
   - 기음 + 배음의 조합이 악기마다 다르다.
   - 어떤 소리에 DFT(푸리에 변환)을 수행하면 그 소리를 구성하는 정현파 구성을 알 수 있다.
   - **엔벨로프** : 악기 소리의 음량변화. 기음, 배음 못지 않게 음색에 큰 영향을 줌.
6. **Loudness**
   - 오직 심리적인 개념
7. **Reverberation, 반향**
   - 나와 음원사이의 거리, 나와 음원사이의 공간을 인지하게 해준다.
   - 즉, 음악엔 공간감이 있다.

## 디지털 소리

### 샘플링

#### Nyquist Theorem

: 샘플을 얼마나 자주 해야하는가?

- 적어도 타겟신호 최대 주파수의 두 배 이상 빈도로 샘플해야 함.
- **Sampling Rate** : 샘플링 주파수
- **Nyquist Rate** : f2는 음원의 최대, f1은 음원의 최소 주파수. **가청 주파수에서 f1은 0으로 생략가능**.
$$
2(f_2 - f_1)
$$
- **Nyquist Frequency** : 샘플링 결과물에서 복원할 수 있는 주파수 = Nyquist Rate/2
  
#### Aliasing Effect
: Nyquist Theorem을 지키지 않을 경우?
- 4Hz 타겟을 4Hz 빈도로 샘플링하면 항상 같은 값이다. (주파수 0)
- 4Hz 타겟을 6Hz 빈도로 샘플링하면 2Hz의 저주파 신호가 나온다.
- **Nyquist Rate 이하로 샘플하면 저주파 신호가 나온다**
- Alias 주파수 = 샘플링 주파수 - 원본 주파수
  $$
  when,f<f_{sample}<2f \\
  f_{alias} = f_{sample} - f
  $$
  
- 8kHz 샘플링일 때 0~4k는 앨리어싱 없다. 4~8k는 위 수식대로. 8k~는 앞선 패턴의 반복이다.


#### 푸리에 변환
: **시간 공간**의 신호를 **주파수 공간의 신호**로 변환한다.


$$
s = g(t) => s = h(f)
$$

#### 악기의 샘플링
- 악기의 가운데 A음 = 기음(440) + 배음
- 악기를 1000Hz로 샘플링하면 잘 될까?
- 놉! Nyquist Frequency가 500Hz라서 **배음이 복원 안 된다**.
- 따라서 기음만 들리는 이상한 음이 된다.

#### 악보 샘플링

- 도(528)-도(1056)-도(2112)-도(4224)
- 음들이 세 옥타브 범위에서 논다고 가정하면 4kHz 샘플링으로 **기음은 충분히 커버**
- 그러나 고주파 **배음들은 사라진다**.

### 양자화

- **샘플 값들을 제한된 값으로 표현**한다.
- 구간으로 균일하게 나누어서 각 구간의 **"중간값"**을 사용
- 이 때, 샘플값과 양자값의 최대 오차를 구간의 절반으로 낮출 수 있다.

#### 양자화 비트 & 오차

- 비트 수가 적으면 구간이 적다 = 구간 크기가 크다 = 노이즈도 커진다
- 비트 수가 많으면 구간이 많다 = 구간 크기가 작다 = 노이즈도 작아진다
- 4비트 양자화 : 16개의 구간
- 16비트 양자화 : 2^16개의 구간

#### Analog Digital Conversion (ADC)
: 아날로그 신호를 디지털로 변환하기

1. 로우패스 필터

   만약, 8kHz로 샘플링 한다면 4kHz 보다 높은 주파수인 신호는 무시하겠다는 뜻
   가청주파수가 20kHz 까지니까 40kHz로 샘플링하면 로우패스필터 안 써도 될 까?

   놉. 귀에 안 들리는 고주파인 **울트라소닉이 가청 주파수 영역으로 샘플링 되어 노이즈가 된다**. (앨리어싱)
   
2. 샘플링

3. 양자화

   **bps** = 양자화 비트수 * 샘플링 주파수 * 채널 수

   **오디오 용량** = (bps * 음원길이 / 8) Byte

   **음질** = 샘플링 주파수와 양자화 비트수에 비례함

4. 부호화

#### 선형 양자화 기법

양자화 구간 간격이 동일하다.

#### 웨버의 법칙

사람이 인지하는 차이는 **자극변화량 / 자극**이다. 즉, 자극 차이를 상대적으로 인지한다.

10dB -> 20dB 이면 1을 느끼고

100dB -> 110dB 이면 0.1을 느낀다.
$$
dr = kds/s
$$


따라서 작은 소리의 차이에 더 민감하므로 **작은 소리 구간을 세세하게 나누는 게 좋다**.

#### 비선형 양자화 기법

작은 소리에 사람이 민감하게 받아들인다는 사실을 고려한 기법. 그러므로 양자화 노이즈가 윗 구간보다 아랫구간에서 더 인지되니까. 양자화를 개선하는 법이다.

- 리스폰스 함수는 log 그래프를 따른다.

- 뮤-로우 : 자극-response함수
- A-로우 : 자극-response함수
- 뮤-로우나 A-로우 함수를 선형으로 양자화 하면, 시그널이 자연스레 비선형으로 양자화 된다.
- 비선형으로 양자화하면 사람이 귀로 듣기에 양질의 사운드가 된다.



1. **PCM**

   샘플을 양자화 시킨 결과값을 그대로 비트로 표현한다.

   - **Low-pass Filter** : 저주파 신호만 통과시킨다. 고주파의 앨리어싱을 방지하기 위해서
   - **Compressor** : 리스폰스 함수에 신호를 통과시킨다.
   - 값의 구간을 나누고 그 구간의 대푯값을 정한다. 보통 평균으로 하겠지?
   - 구간을 나눠주는 기준값들이 **Decision Boundaries**
   - 구간의 대푯값들이 **Reconstruction Levels**
   - Decision Boundaries를 표로 만들어 준 것이 **Coder Mapping** 테이블
   - 양자화 된 값을 풀어주는 **Decoder Mapping** 테이블
   - 디코더는 양자화 된 리스폰스 값을 대푯값으로 매핑해 준다.
   - Expander : 리스폰스 함수의 역함수를 통해서 본래 시그널을 구한다.

2. **Differential PCM**

   연속하는 샘플값은 큰 차이가 안나더라 -> **차분정보를 활용**해서 비트를 아낀다.

   샘플값 최대 차이를 기준으로 양자화 비트 배정.

   상대적으로 적은 비트수가 필요하다.

3. **DM**

   **무조건 델타만큼 오르고 델타만큼 내린다고** 차분값을 가정한다. 위 아래 방향만 제시한다.
   
4. **ADPCM**



### 부호화

#### Loseless Predictive Coding

앞 선 자료의 값을 사용해서 현재 값을 예측한다. 예측값과 실제값의 차이값을 전송하면 된다. 적은 용량이 필요하다.
$$
\hat{f_n} = predictor(f_{n-1},f_{n-2},f_{n-3}, ...) \\
e_n = f_n - \hat{f_n}
$$

- 오차의 범위는 (MAX - min) 인데 어쩌지?

  히스토그램을 보고 자주 등장하는 오차에는 적은 양자화 비트를 할당하고, 거의 등장하지 않는 오차에는 큰 양자화 비트를 주면 됩니다.

- 앞에 나온 몇 가지 값들을 선형조합 하여 지금 값을 예측할 경우

$$
\hat{f_n} = polynominal(f_{n-1},f_{n-2},f_{n-3}, ...) \\
$$

- 오차가 나올 수 있는 범위를 정한다. 그럼 코드북을 작성할 수 있다.
- 오차의 범위로 커버할 수 없는 오차는 SU/SD 시그널로 커버할 수 있다. ㅎㅎ
- 짧은 비트로 많이 등장하는 오차를 표현하고, 드물게 등장하는 오차는 큰 비트를 사용할 수 있다.
- 맨 처음 시그널은 그냥 보낸다.

#### DPCM의 부호화

에러를 보낼 때 양자화 시켜서 보낸다. 양자화 시킨 에러를 사용하므로 복원한 값은 실제 샘플값과 달라지게 된다.
$$
\hat{f_n} = predictor(f_{n-1},f_{n-2},f_{n-3}, ...) \\
Q(e_n) = Q(f_n - \hat{f_n})\\
$$

#### DM의 부호화

오차가 음수이면 -d로 양자화하고, 오차가 양수이면 +d 양자화한 다음 전송한다.

#### Adaptive DM의 부호화

올리고 내리는 차이는 상황에 따라 변한다.

#### ADPCM

