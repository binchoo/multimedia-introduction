# Video 압축

##  비디오 스탠다드

> 예전엔 두 그룹이 양분해서 스탠다드를 발표하다가
>
> Joint Video Team을 구성해서 동일한 스펙을 만들고 각자 출판한다.
>
> H.264만 해도 너무 복잡하다. H.261, 263, 264, MPEG-1 순차대로 알아가야 한다.

### ITU-T : `H.` 으로 시작함
1. **H.261** : 전화선 기반 ISDN에서 사용하기 위한 동영상 포맷.  ISDN 망은 64kbps 회선 여러개를 묶어서 광대역을 지원한다. 그래서 H.261은 64kbps의 배수를 지원한다.
2. **H.262** : **MPEG-2**랑 동일하다.
3. **H.263** : PSTN이라는 공중 아날로그 전화망을 타겟으로 한 포맷이다. 20k~2Mbps이므로 응용범위가 넓다. 
4. **H.264(MPEG-4 AVC)** : 범용 고능률 영상
   - **MPEG-4 AVC**과 동일한 조인트 포맷이다
5. **H.265** : 4년정도 전에 생김. 최근 캠코더라던가
### MPEG : `MPEG` 로 시작함
  1. **MPEG-1** : 1.5Mbps 지원. CD-ROM에 비디오를 올리기 위한
  2. **MPEG-2** : 4~30Mbps 지원. 고품질 범용 영상
  3. **MPEG-3** :  MPEG-2 에서 다 지원한다
  4. **MPEG-4** : 멀티미디어 방송 범용, 근데 방속에서 쓰는 걸 본적이 없다고 한다. 기본 코덱이 H.263과 같다. 그래서 두 포맷이 혼용되었다.
  5. **MPEG-4 AVC** : 지상파 DMB 영상. 우리나라 휴대폰은 재난시 전파를 위해 DMB를 포함하고 있다. 디지털 캠코더들이 사용하던 포맷

### De Facto Standards

시장 장악력을 기반으로 한

- Adobe Flash FLV formats

- Google VP1, VP2 formats

## Video의 특성

**Temporal Redundancy**

- 오디오는 시간축 상에서 시간 샘플 발생. 비디오는 시간축 상에서 이미지 발생

- 오디오는 시간적 중복성을 갖는다 비디오도 비슷하다. 앞 프레임과 뒷 프레임 간의 차이는 물체의 움직임, 카메라 움직임, 조명이 바뀌는 만큼이다.

- 그러므로 비디오도 차분하여 압축한다면 좋은 압축률을 낼 수 있을 것이다. (엔트로피가 낮아지므로)

- 그냥 차분을 나누는 것 보다 좋은 방법은? 뺄셈연산을 하기 전에 픽셀들을 적절히 이동시킨다음 빼겠다.ㅋㅋㅋㅋㅋㅋㅋ

  => Motion Compensation에 기반한 비디오 압축

**Spatial Redundancy**

- JPEG의 DCT 활용과 같음

## Motion Compensation

움직임이 발생한 지점을 다 보상하기 위해서 Reference를 참고하여 압축.

- Reference Frame : 앞 선 프레임

- Target Frame : 압축하려는 현재 프레임

#### 모션을 찾는 기준

1. 어떤 움직임이 발생했느냐? 벡터로 표현 : ""이 오브젝트는 이 위치에서 왔어"
   - Optical Flow : 픽셀 기반, 각 픽셀값들이 앞에 프레임의 어느 픽셀에 있던 값인지 찾는다. 
     - **연산량이 굉장히 큼**
     - 모션벡터를 다 구축학 되면 용량이 ;;
     - ***배보다 배꼽이 크네 ㅋ***
   - 오브젝트 기반, 어떤 객체가 앞의 프레임의 어느 위치에 있었는지 표현한다.
     - **객체를 따오기가 힘드네?** 오~ 포토샵에 Object Segmentation 기능 있음
     - 구현하고 적용하기 힘든 기술
     - 기상청 아나운서 인체 따오기 : 크로마 키를 제거해서 합성된 이미지를 덧대는 것
   - **덩어리(매크로 블록) 기반**, 픽셀과 오브젝트 사이의 타협점. 
     - **타겟 매크로 블록**과 **가장 비슷한** **레퍼런스 매크로 블록**을 예측함
     - 보통 16 x 16 블록을 사용한다
     - 4:2:2 서브샘플링한다면 크로미넌스는 16 x 8 블록을 사용한다.
     - 4:2:0 서브샘플링한다면 크로미넌스는 8 x 8 블록을 사용한다.
     - **모션벡터** : 가장 유사한 레퍼런스 매크로 블록 & 타겟 매크로 블록의 위치 차이
     - 예측을 진행하는 방향을 순방향으로 해도 되고, 역방향으로 해도 된다.
     - Search Window를 두어서 해당 범위에서만 Reference Macro Block를 찾는다.
     - MAD : 두 블록의 유사한 정도를 결정내리기 위한 지표. 이 값이 최소일 때 유사한 블록으로 간주한다.
     - MAD를 가장 작도록 하는 (i, j)를 모션벡터라 한다.
2. 예측치와 실제값의 차이를 구함
3. 차이값을 사용하여 부호화한다.



### Motion Vector Search 알고리즘

- x, y, offset <i, j>으로 구성
- Reference 영상에서 Target과 매치 되는 블록이 어딨는지 알려준다.
- 매치되는 블록끼리 빼서 DPCM 하고 Huffman Coding 한다

1. Sequential Search

   - 윈도우에 포함된 이웃 블록에 대해서 MAD를 계산한다. 가장 연산량이 많은 Motion Vector Search 알고리즘이다.
   - 윈도우는 (2p+1)*(2p+1) 크기이고 p는 15 혹은 7인 경우가 많다
   - $O(p^2N^2)$
   - 윈도우의 크기와, 매크로 블록의 크기에 대해 제곱에 비례함

2. Logarithminc Search

   - Sub Optimal 알고리즘이다.

- Search Window 

  - 원래 윈도우에서 절반 크기의 윈도우를 잡고
  - +-x, +-y 방향으로 중간 거리에 위치한 9개를 살펴본다.
   - 거기서 MAD 값이 가장 최소인 블록을 고른다.
  - 해당 블록을 중심으로 9개의 블록을 살펴본다.
    - 거기서 MAD 값이 가장 최소인 블록을 고른다.
    - 해당 블록을 기준으로 9개의 블록을 또 잡는다.
    - ...
    - 윈도우 크기가 1이 되어 살필 것이 없을 때까지
   - 연산량을 줄였으나 그럼에도 많다.

3. 3-level Hierarchical Search

   - 큰 이미지를 절반씩 줄여나간다
   - 가장 작은 이미지에서 모션 벡터를 찾는다.
   - 한 단계씩 이미지를 키워나가며 그 주변 픽셀에 MAD가 낮은 값이 있을 것이라 가정한다.
   - 한 단계에서 9개를 찾는 것보다 적은 연산량이 소모된다.

   |                             |      |      |
   | --------------------------- | ---- | ---- |
   | sequence search             |      |      |
   | logarithmic search          |      |      |
   | 3-level hierarchical search |      |      |

#### 예측 에러

- 레퍼런스 블록과 타켓 블록의 차이값

- B 프레임의 경우 뒷 프레임에 대해서도 매크로 블록을 구한다. 
  - 앞의 매크로 블록
  - 뒤의 매크로 블록
  - 평균적인 매크로 블록, 중에서 가장 MAD가 작은 블록을 고른다

#### MAD 역치를 만족하는 매크로 블록을 찾지 못하면 

예측 부호화를 포기하고, 걍 I frame 방식처럼 부호화한다. 

#### Macro Block 코딩되는 경우
- I-MB by I프레임, P프레임, B프레임
- FP-MB by P프레임, B프레임
- BP-MB, B-MB by B프레임

=> B프레임엔 4가지 매크로 블록이 섞여 있군! 역치를 못 넘을 경우에 I매크로 블록임

## 비디오 전처리

1. 컬러 모델 바꾸기

   YCbCr을 사용하는 경우가 많아서 RGB를 YCbCr로 바꿔줘야 한다.

2. 값이 튀는 것을 막아주는 Low Pass Filtering

3. 컬러 서브샘플링

## 동영상 프레임을 부호화하는 모드

### Intra Mode

- 화면 내 부호화. Reference Frame을 사용하지 않고 현재 프레임 정보만으로 압축
- Temporal Redundancy를 이용하지 않는다. JPEG 압축 하는 것과 비슷하다.
- Spatial은 이용하는가? ㅇㅇ

- 이 방식으로 압축된 화면을 I-frame 이라고 한다.

### Inter Mode

- 과거나(순방향) 미래(역방향) 프레임을 참조하는 예측 압축 방식
- 모션 컴펜세이션, 매크로 블록 사용
- Temporal Redundancy 이용
- p-frame은 순방향 예측으로 압축한 프레임이다.
- b-frame은 순방향과 역방향을 모두 고려하여 압축한 프레임이다.

## Group of Frames 개념

### I frame(Spatial Redundancy 제거)

동영상에서 압축률이 나쁜데도 I-frame을 사용하더라?

- Group of Frame : I-frame으로 시작하는 연속적인 프레임들의 집합이다.

- 중간중간 I-frame을 넣어 GoP를 구성하는 이유는 압축된 프레임에 대해 **Random Access를 지원**해주기 위해서!

- 잘못 복구된 프레임을 참조하여 **에러가 전파되는 현상을 막기 위해**서!

- 다른 프레임에 의존하지 않는 독립적 프레임이라 가능한 일.

> streaming format은 intra mode를 사용하지 않았기 때문에 중간부터 보려면 앞에 있는 모든 장면을 디코딩 해야했다. ㅜㅜ
>
> i-frame을 넣어서 그 프레임부터 재생하는 방법이 생겼다
>
> 좋은 디코더들은 i-frame부터 사용자가 요청한 프레임까지 디코딩해서 보여준다!

### P frame

- 순방향으로 예측하여 압축한 프레임
- 모션 컴펜세이션을 사용하여 상대적으로 높은 압축률 제공
- **I 와 I 사이에 P 프레임 개수를 제한을 건다.** P 프레임이 길어질 수록 UX 퀄리티가 떨어지고 에러가 누적되니까
  - MPEG은 1초에 I 프레임 2~3장을 권장하고 있다.
- P 프레임은 B프레임을 참조하면 안 된다. **순환참조가 일어나기 때문이다.**

### Bidirectional frame

- 이전의 영상, 다음 등장하는 I, P 프레임을 참조하여, 둘을 평균한 MB 총 3개의 MB중 좋은걸로 예측
- 가장 압축률이 좋다.
- 역방향 참조가 괜찮은 이유는 앞 프레임에 가려졌던 얼굴이 뒤쪽 프레임에서 등장할 수도 있기 때문이다.

## GoF 부호화 순서

- I B B P 일 때 I, P를 먼저 부호화 해서 B 프레임이 양방향을 참고할 수 있도록 한다

- 그래서 파일에 저장될 때는 I P B B 순서로 저장되어 있다.

**영상 재생 순서와 실제 처리 순서가 다르다!**



## 그냥 차분 vs 움직임 보상 + 차분

- 움직임 보상을 적용하니 배경 차분이 노이즈 없이 까맣게 나오는 걸 알 수 있음

# 화상통신을 위한 H.261

frame 하나를 추상화 하길

 (1, 3, 33, 6, 64) = (F, 3GoB, 33MB, 6B, 64Component)

## 특징

- 화상 통신을 타겟으로 하였음
- 그래서 굳이 Random Access 기능이 필요하지 않았으며
- 딜레이 300ms 이내로 유지하는 것이 성능 지표였다.
- QCIF를 필수로 지원하고 CIF를 선택적으로 지원한다.  

## GoB

- MB를 가로로 11개, 세로로 3개로 묶어 놓은 것임
- GoB가 3개 이면 CIF 352*288과 딱 맞아 떨어진다
- **에러가 발생했을 때 화면을 복원하기 위해 사용**

## 데이터 플로우 아키텍처

- Source Coding : 이미지, 오디오 컨텐츠를 코딩, **데이터를 압축**
- Channel Coding : 통신단에 얹는 정보들. 오류정정, 오류탐지, 오류복원을 위한 정보. **데이터를 늘리는 원인**
- 복호기
- **영상신호 다중화기 : 매크로 블록을 합쳐서 스트림을 만든다**
- 역 다중화기
- 송신 버퍼 : 스트림을 담는 버퍼.
- 부호화 제어기 : 부호기 비트레이트를 조정하여 송신 버퍼가 원하는 비트레이트에 맞춘다

## 부호화 방식

### MVD

모션벡터 조차 그냥 전송하지 않는다. 모션 벡터끼리도 DPCM 한다. 

MVD = 앞 매크로블록의 모션벡터 - 현재 매크로블록의 모션벡터

### 양자화

- 양자화 코드표를 사용하지 않는다. 양자화 제어기가 설정하는 Step Size = scale * 2 **상수**를 사용한다
- DC 컴포넌트는 항상 8로 나눈다.
- 비트레이트를 조절하는 방법은 양자화 스텝 크기를 바꾸는 것이다.
  - $R = 1/D = M = 1/DELL$
  - 스텝 크기 넓다 = 비트레이트 감소
  - 스텝 크기 작다 = 비트레이트 증가

### I 프레임 양자화

### P 프레임 양자화

### 부호화 제어기

- 부호화 제어한 정보는 비트스트림에 포함된다. 디코더가 그 정보를 알 수 있다.

### 프레임 계층 구조

QCIF (1F, 3GoB, 33MB, 6B, 64Component)

CIF (1F, 12GoB, 33MB, 6B, 64Component)

- PSC : 프레임 시작
- TimeReference : 해당 프레임이 시간 상에서 언제 재생되어야 할 지 알려준다. 디코더가 언제 프레임을 뿌릴 지 알게 해준다
- PType : 어떤 종류의 프레임인지
  - GBSC : GoB 시작
  - GN : 몇 번째 GoB인가
  - GQuant : GoB 전역 양자화기
    - MQuant : MB 양자화기 GoB 양자화기 오버라이드 가능
    - MVD : 차분모션벡터
    - CBP : 매크로 블록을 코딩할 필요가 없다는 것을 알려준다, 보통의 경우 그렇지 않고 cb cr 블록이 따라온다. 

# 약간 발전한 H.263

> PSTN이라는 공중 아날로그 전화망을 타겟으로 한 포맷이다. 20k~2Mbps이므로 응용범위가 넓다. 
>
> MPEG-4 랑 비슷한 시기에 나왔다.

## 특징

- 타켓 비트레이트 : 낮은 전송률
- 타겟 망 : PSTN 
- 타겟 어플리케이션 : Visual Conference
- H.324 시리즈에 포함 : 오디오 비디오 셋업.. 프로토콜 모음. 그 중 비디오 프로토콜이 H.263임
- 컴퓨팅 성능 개선 -> 복잡한 계산 가능 -> H.261 보다 개선
- H.261을 베이스로 두고 있기 때문에 H.261의 한계를 그대로 지니고 있었다
- H.261은 움직임 보상을 할 때 모션벡터 서치 할 때 한 픽셀씩 이동했으나
  - H.263은 절반 픽셀 씩 이동하는 것이 가능하다
- 비트스트림 일부분이 선택사항이 되면서 **오류복원에 더 신경**쓸 수 있음

## 늘어난 지원 비디오 포맷

- sub QCIF : QCIF 보다 더 작은 이미지 => 64kps
- QCIF : 261에서 지원하던 것. 64kps
- CIF : 261에서 지원하던 것.

- 4CIF : 비트레이트 높은 형식도 지원함
- 16CIF : '', 1Mbps

## 포맷별로 다른 크기의 GoB

H.261과 차이점

- sub-QCIF, QCIF, CIF, 4CIF, 16CIF를 위한 GoB 개수와 크기가 다르다
- 단, GoB는 프레임 왼쪽에서 시작하고 오른쪽에서 끝나는, 줄 모양을 지킨다
  - sub-QCIF : 6GOB
  - QCIF : 9GoB, 11x1 MB
  - CIF, 4CIF, 16CIF : 18GoB, which respectively has difference size.
  - 4CIF GoB = .x2 MB
  - 16CIF GoB: .x4 MB

## 주위 3MV로 예측하여 MV부호화

- 현재 MB의 MV를 주위 3MB의 MV1, MV2, MV3를 참고하여 예측

  - 세 벡터를 보고 미디안 값을 예측 MVp의 원소로 삼는다
  - 세 벡터라 함은 left, top, right top MB의 MV
- 현재 MB가 이미지 경계, 혹은 GoB 경계에 맞닿아서 이웃이 없다면?
  - 그 위치의 벡터를 (0,0)으로 취급하거나 살아있는 이웃의 MV값을 복사한다

## Half-Pixel Precision 지원

  - 절반 픽셀(?) 개념 : 프레임을 두 배 뻥튀기 하고 보간법 적용
  - 두 배로 늘린 공간에서, 한 픽셀씩 움직이며, MAD가 가장 작은 MB를 찾겠다는 의미이다

## 다양한 모드 지원

- Unrestricted Motion Vector Mode
  - 경계 근처의 MB를 예측할 때 서치할 곳이 이미지 밖으로 삐져나가게 된다
  - 밖으로 나간 바운더리에 가장 **가까운 픽셀 값을 복사해 넣는다**
- Syntax Based Arithmetic Coding
  
  - 허프만 코딩을 대체하여 **Arithmetic 코딩을 사용하게** 된다
- Advanced Prediction Mode
  
  - 모션 예측을 8x8 MB 단위로 한다
  - 그래서 16x16에서 4개의 MV가 도출된다
  - 하나의 블록을 위한 벡터는 자신의 벡터 + 이웃의 두 벡터의 weigted sum이다
- PB-frame Mode
  - P프레임과 B프레임을 하나로 합쳐 코딩하는 이상한 프레임
  - 성능이 별로라 잘 안 쓴다
  - 스무스한 영상에 효율

