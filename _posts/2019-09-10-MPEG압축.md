## MPEG 표준들

- MPEG-1 타겟 : CD에 **저장하는 미디어**
- MPEG-2 타겟 : 통 신, DVD 저장, **방송매체** 동영상 압축표준
- MPEG-3 = MPEG-2
- MPEG-4 타겟 : 낮은 비트율로 객체 중심의 동영상 압축
- MPEG-7 : 멀티미디어 검색에 쓰일 메타데이터 표준을 만들었다
- MPEG-21 : 멀티미디어 프레임워크

# 임의 접근이 필요한 MPEG-1

## MPEG-1 타겟 : video, audio system

엠펙은 비디오와 오디오 멀티미디어를 위한 표준

Elementary Stream

Program Stream : 프로그램은 TV 프로그램 처럼 어떤 컨텐츠를 말한다. 프로그램 스트림은 여러 컨텐츠를 멀티플렉싱한다

## H.261 vs MPEG-1

### 양방향 프레임 모드 추가

- I프레임, P프레임, **B프레임**

### 지원 포맷 추가

- QCIF, CIF 이외에 **SIF,** **조건을 만족하는 프레임** 구조를 정의해서 지원한다

### Slice 개념 사용

- GoB보다 유연한 모양새
- 매크로 블록의 개수를 디자이너 맘대로!
- 개별적인 양자화 테이블 사용가능
- 그래서 유연하게 비트레이트 조정가능

### 모드 간 다른 양자화기 사용

- Intra 모드는 상수로 나누는 양자화기
- **Inter 모드는 상수가 아니다**.

### 더 넓은 모션예측 윈도우 지원

- p=15 VS **p=512** (p=1024 for half pixel precision)
- **반 픽셀 단위**로 모션예측 가능

### 임의 접근 가능

- 비트열 수준에서 프레임을 랜덤 액세스 가능
- **GoP의 헤더에 프레임이 해당하는 시분초 정보가 첨가되어 있음!**

### 화면 누락 없는 비트레이트 조절

- H.261은 비트레이트를 조절하기 위해 화면을 누락하기도 함. 
- MPEG-1은 **화면 누락이 없다.** 

??

- MB 타입이 프레임 타입에 의해 결정 vs 화면유형별 MB 타입 

### 공통점 = 부호화기

- 2차원 VLC를 사용한다
- DCT를 사용한다

## 프레임 계층 구조

시퀀스 (=비디오)

(1시퀀스, ?GoP, ?Picture, ?Slice, ?MB, 6B, 64C)

- 시퀀스 헤더
- 연속되는 GoP(그룹 오프 픽처)
  - 15장 안팎의 Picture : I - > P -> B ... -> I
    - 슬라이스
      - 임의 갯수의 매크로 블록
        - 여러 개의 블록
          - 첫 째 DC값 및 run length 코딩 된 값

# 방송을 고려하는 MPEG-2

방송을 고려하다 보니 에러에 더욱 집중, 인터레이스 지원, 다중화된 전송 **시스템**

### 다중화 시스템

에러를 처리하기 위해 필요한 시스템

#### Packetized Elementary Stream(PES)

컨텐츠를 전송하기 편하게 패킷화 해준다

#### Transport Stream(TS)

에러정정을 위한 정보를 추가해서 멀티플렉싱 해주는

### Scalable Coding (Layered Coding)

1. **Base Layer** : 최소한 필요한 정보만 담은 패킷. 양자화기를 제어해서 열화시킨다.
2. **Enhancement Layer** : 화질 향상을 위한 부가정보를 담은 패킷. Base와 화질 좋은 것 간의 차잇값

두 레이어 간의 우선순위 : Base 먼저 보내고 여유로울 때 Enhancement 보냄

네트워크가 여유로울 경우 : 디코더는 두 레이어를 모두 받는다

네트워크가 힘들면 : Base만 받아서 열화된 화질로 영상을 복원한다

### MPEG-1 하위호환 가능
### 인터레이스드 영상 고려

  - 프레임 픽처 = 홀수 필드 픽처 + 짝수 필드 픽처

  - 필드 픽처 

    프레임 픽처의 홀수 라인과 짝수 라인을 구분한 개념

- 프레임 모드 

  MB를 4개의 B로 원래 하던 것처럼 쪼개단다

- 필드 모드 

  MB를 4개의 B로 쪼갤 때 같은 필드의 픽셀끼리 모아서.

  짝수 필드 블록 2개 + 홀수 필드 블록 2개

  - 8*8 블록을 취하면 프레임 모드인지 필드모드인지 알 수 있음.

#### 프레임 예측과 필드 예측과 5가지 예측 모드 

1. **Frame을 코딩하기 위해 Frame으로 예측**

   MPEG-1에서 사용하는 방법을 똑같이 써라. **16x16**

2. **Field를 코딩하기 위해 Field로 예측**

     Top field는 앞 필드 픽처의 Top과 Bottom field를 참고해라

     Bottom field도 앞 필드 픽처의 Top과 Bottom field를 참고해라 **16x16**

3. **Frame을 코딩하기 위해 Field로 예측**

   16x16 MB를 **16x8** 두 개로 쪼갠다. 각각은 Top, Bottom에서 온 픽셀들이다.

   **단, Top은 앞의 Top을 봐야하고 Bottom은 앞의 Bottom만 봐야한다.**

   하나의 MB에 모션 벡터가 2개 생기고 성능이 좋아진다.

   양방향 예측하는 B프레임은 4개의 모션벡터가 생긴다 ㅎ

4. **Field를 코딩하기 위해 Field로 예측하되 모션 벡터 두 개 뽑아라**

   16x16을 **16x8**로 쪼갠다. 각각은 Top과 Bottom에서 온 픽셀들이다.

   앞의 필드를 보고 2개의 모션벡터를 구하여 예측한다. 불규칙, 급박한 영상에 좋다

5. **P 타입을 코딩하기 위해 Dual Prime 으로 예측**

   각자 똑같은 앞 필드로 예측하여 MV1, MV2얻고, 앞 다른 필드와 쿵짝쿵짝 CV를 얻고, MV와 CV로 쿵짝하여 얻은 두 에러의 평균에러 쓰게 된다.

#### Temporal *Scaling*

모션 벡터를 계산할 때 **같지 않은 필드**를 참고해도 좋다. 그럴 때 시간차가 얼마 나는지 계산 조심해라

#### Alternate Scan

인터레이스 된 영상이라서 세로 방향으로 연관성이 적다.

세로 방향의 에러가 좀 커지더라. 

Alternate Scan은 스캐닝을 할 때 세로 방향을 좀 더 우선적으로 스캐닝 한다.

#### 프레임 픽처, 필드 픽처 다양한 조합으로 예측이 가능한 이유

- Top과 Bottom은 겨우 1/60초 차이
- 수직으로 겨우 1픽셀 차이
- "Parity가 같은 픽처 끼리" OK
- "Parity가 다른 픽처끼리" 역시 OK
- 필드의 개념이 생겨나니까 예측 방법이 늘어남!
- B프레임은 참고하지 않는다. **MPEG-1, MPEG-2는 B프레임 참고할 일 없음**

### Profile과 Level 개념

#### Profile

- MPEG-2는 **범용**! 다양한 응용을 지원 -> 다양한 기술이 필요
- 엔트로피 코딩을 할 때 어떤 툴을 쓸 것이냐? 양자화 할 때 어떤 툴을 쓸 것이냐? 
- 프로파일은 어떤 툴셋을 지원하는지 알려준다
- 애플리케이션 도메인에 따라 코덱의 프로파일을 다르게 사용한다
- 어떤 툴셋을 쓰느냐에 따라서 압축의 성능과 기능이 달라진다
- 프로파일이 서로 다르면 호환되지 않을 수 있다

#### 호환성

SIMPLE PROFILE < MAIN PROFILE < HIGH PROFILE

하이는 심플 프로파일로 코딩된 것을 디코딩할 수 있다

#### Level

툴을 이용할 수 있는 패러미터 값 제한이다



# 객체지향 MPEG-4

### User Interaction 지향

- Interactive Media : 웹에 올라갈 유저 친화적인 미디어. 사진에서 원하는 정보를 빨리 빨리 뽑아낼 수 있다.
- Interaction : 유저가 장면이나 오디오 등의 **객체**들을 조작 할 수 있음
- BIFS : 객체들을 조합하여 씬을 구성하는 것에 대한 정보
- 5kbps~10kbps : 훨씬 낮은 비트레이트에서 **다양한** 컨텐츠를 지원하고싶다
- 정말 가능할까?? 목적에 맞는 다양한 툴 셋(**Profile**)을 지원하면 되지~

### 블록/프레임 기반에서 객체/VOP 기반으로

- 객체기반 : 사진에 등장하는 **객체를 따로 따로 코딩**하고, 그들의 **위치정보**도 코딩. 디코딩 할 때 합친다.
- 압축률이 올라간다.
- 객체들 위치를 변형하고 합성하는 재미난 일을 수신단에서 할 수 있다.

### Scene 개념 = {시각, 청각}

- 비주얼 씬 : 자동차를 내가 원하는 곳에 배치할거야
- 오디오 씬 : 자동차를 옮겼으면 뭐해 **음원**의 위치도 같이 옮길거야
- 씬 조정은 MPEG-1/MPEG-2 인코더가 할 수 있기는 함 (구현되어 있나? ㅎㄷㄷ)
- MPEG-4는 디코더 단에서 유저 원하는 대로 하자는 것이다.

### 아키텍처

> JPEG : (1Picture, nScan, nSegment, 6Block, 64Component)

> H.261 : (1Picture, 12GoB, 33MacroBlock, 6Block, 64Component)

> MPEG-1 : (1Sequence, nGoP, nPicture, nSlice, nMacroBlock, 6Block, 64Component )

> MPEG-4 : (1비주얼시퀀스, n비디오 오브젝트, n비디오 오브젝트 레이어, n그룹 오브 비디오 오브젝트, n비디오 오브젝트 플레인 )

- VS : 비디오 오브젝트 시퀀스
- VO : 비디오 오브젝트
  - 씬을 구성하는 여러 개의 오브젝트 중 하나를 일컫는다. 오브젝트란 사물 뿐만 아니라 오디오도 일컫는다.
- VOL : 비디오 오브젝트 레이어
  - 그룹 오브 디비오 오브젝트를 어떻게 인코딩할 것인지.
- GoV : 그룹 오브 비디오 오브젝트 플레인
  - 랜덤 액세스를 가능하게
- VOP : 픽처 대신에 비디오 오브젝트 플레인!
  - 특정한 순간 비디오 오브젝트의 스냅샷이다.

따라서, 최상위 레이어는 시퀀스, 그 및에 여러 개의 사물들, 각 사물에 대한 레이어들, 그 속에 존재하는 플레인들, 그 중 하나인 오브젝트 플레인

### 프레임 대신에 Video Object Plane

- I-VOP

- P-VOP 

- B-VOP 

### 단점 

- 객체이기 때문에 모양이 제멋대로다. **모양 정보도 같이 코딩**해야 한다

### Motion Compensation 과정

- 객체에 기반한 모션 예측, 모션 보상, 모양 코딩을 한다
- 바운더리 박스 : VOP를 감싸는 네모난 박스
- MB : 루마 16x16, 크로마 8x8
- 인테리어 MB : VOP에 완벽히 들어있는 MB
- 엑스테리어 MB : VOP에 전혀 포함되지 않은 MB
- 바운더리 MB : VOP의 경계에 놓인 MB
- 패딩 : VOP에 속하지 않는 픽셀에 특정값을 메꾼다

1. **Minimum 바운더리 박스**를 구하기

   박스 크기는 **16배수**여서 MB로 쪼개질 수 있다. **VOP가 없는 MB가 발생할 수 있다.**

2. 엑스테리어 MB를 **제거**한다.

   레퍼런스 VOP에서는 필요없는 과정이다

4. 패딩
   레퍼런스 VOP의 바운더리 MB에서 비어있는 픽셀에 **특정 값**을 넣어준다

   경계를 기준으로 평균한 값을 쓴다. 타겟 VOP에서는 필요없는 과정이다.

5. 모션 벡터 계산

   **SAD** 지표를 최소로하는 벡터를 구한다. 식은 **MAD**랑 비슷하다.

   모든 픽셀이 아니고, 오로지 **VOP에 속한 픽셀**만 따져서 계산된다.

### 텍스처 코딩

1. 그냥 DCT
    DCT로 선형변환하여 VLC 코딩한다. 
- 인테리어 MB를 코딩하려면
  하던 대로 하면 된다
- 바운더리 MB를 코딩하려면 
  !VOP 픽셀에게 0을 매긴다

2. **Shape Adpative DCT**

   객체 안쪽에 있는 영역만 DCT하자! 8x8 네모 말고..

   바운더리 MB에 들어있는 모양이 일정하지 않기 때문에 **x 방향, y 방향으로 두 번의 DCT-N 적용.**

   - 영역에 들어있는 픽셀을 위로 탁탁 털어서 모은다. axis0 별로 적합한 n-point DCT를 수행한다.

   - 이제 픽셀을 왼쪽으로 탁탁 털어서 모은다. axis1 별로 픽셀에 적합한 n-point DCT를 수행한다. 

### Shape Coding

객체 모양을 알려줘야 하니까. 

**16x16** 기준으로 코딩한다

- **바이너리 알파맵** : 객체 부분은 1, 아니면 0으로 표기한 맵

  0이 연속되거나, 1이 연속되는 경우가 많으니 RLC를 적용! **MMR이란 방법을 사용한다.**

- **그레이스케일 맵** : 해당 픽셀의 투명도를 얘기함. 알파채널에 들어가는 값. 0(투명) ~ 255(불투명)


### Modified Modified READ (MMD)

Binary Shape Coding 하는 법

0이 얼마나 지속되는지. 1이 얼마나 지속되는지 정보를 활용하는데..

- $a_0$ : 코덱 둘 다 알고 있는 최근의 픽셀 값. **예시로 0이라 하자.**
- $b_{1}$ : 전 라인에서 $a_0$ 와 다른 값을 가지고 있는 첫 픽셀
- $b_2$ : 값 변화 픽셀
- $a_{1}$ : 값 변화 픽셀 1. 코더만 알고 있지
- $a_{2}$ : 값 변화 픽셀 2. 코더만 알고 있지

#### 코딩 모드

1. **Vertical Mode**

   라인 별로 런길이가 비슷할 것이다. a0와 a1간의 거리보다 b1과 a1 간에 런으로 코딩하자.

2. **Horizontal Mode**

   라인 별로 런길이가 안 비슷할 것이다. 그냥 같은 라인에 대해서 런코딩한다.

3. **Pass Mode**

   a0 ~ a1 사이에 b1 ~ b2가 있다. 적어도 b2까지는 같은 값이겠지?
   
   a0를 b2위치로 옮기고 그 이후부터 코딩을 하자.

#### 기존의 Modified READ

- a1과 b1 간 차이가 3보다 작으면 무조건 **Vertical Mode** 적용
- 에러 전파를 막기 위해 **K줄** 만큼 **Vertical Mode**를 사용했으면 **Vertical Mode**를 사용할 수 없다.

#### Modified Modified READ : K팩터 없앰

- 16x16을 단위로 코딩하기 때문에 길어봤자 16라인 에러전파.
- 굳이 에러에 대한 걱정을 하지 말자. K Factor 제한을 쓰지 말자.

### Context-based Arithmetic Encoding (CAE)

Context란, 타겟 픽셀의 주변 픽셀을 고려해서 코딩한다는 의미

#### 코딩 모드

1. **Intra Mode**

   타겟 픽셀 주변의 10개 픽셀을 고려

2. **Inter Mode**

   레퍼런스 픽셀의 주변 5개
   
   타겟 픽셀 주변 4개 
   
   = 총 9개 픽셀을 고려

### Sprite Coding

**Sprite**란, 이미지 안에서 마구 움직이는 이미지이다.

현실 세계의 **움직이는 객체**와 정적인 배경을 분리한다.
